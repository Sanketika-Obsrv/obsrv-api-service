{
  "configs": {
    "alerts": {
      "dataset_metrics_flink": [
        {
          "metric": "sum(sum_over_time(flink_taskmanager_job_task_operator_ExtractorJob_dataset_id_extractor_failed_count[5m])) + sum(sum_over_time(flink_taskmanager_job_task_operator_ExtractorJob_dataset_id_extractor_duplicate_count[5m])) + sum(sum_over_time(flink_taskmanager_job_task_operator_PipelinePreprocessorJob_dataset_id_validator_failed_count[5m]))",
          "alias": "[DATASET]: Detected high rate of invalid data than expected",
          "category": "Processing",
          "severity": "critical",
          "code": "PROCESS_DATASET_002",
          "description": "A high rate of invalid data can disrupt processing pipeline reduce data quality and lead to inaccurate insights in downstream analytics and reporting",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "sum(sum_over_time(flink_taskmanager_job_task_operator_PipelinePreprocessorJob_dataset_id_dedup_failed_count[5m]))",
          "alias": "[DATASET]: Detected higher rate of duplicate data than expected",
          "category": "Processing",
          "severity": "warning",
          "code": "PROCESS_DATASET_003",
          "description": "A higher rate of duplicate data can inflate storage usage and impact the accuracy of reports and downstream data processing.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "sum(sum_over_time(flink_taskmanager_job_task_operator_DenormalizerJob_dataset_id_denorm_failed[5m])) + sum(sum_over_time(flink_taskmanager_job_task_operator_DenormalizerJob_dataset_id_denorm_partial_success[5m]))",
          "alias": "[DATASET]: Detected higher incidence of failures during data enrichment.",
          "category": "Processing",
          "severity": "critical",
          "code": "PROCESS_DATASET_004",
          "description": "Frequent data enrichment failures can cause incomplete data and affect downstream analytics accuracy.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "sum(sum_over_time(flink_taskmanager_job_task_operator_TransformerJob_dataset_id_transform_failed_count[5m])) + sum(sum_over_time(flink_taskmanager_job_task_operator_TransformerJob_dataset_id_transform_partial_count[5m]))",
          "alias": "[DATASET]: Detected higher incidence of failures during data transformations.",
          "category": "Processing",
          "severity": "critical",
          "code": "PROCESS_DATASET_005",
          "description": "Frequent transformation failures can lead to unmasked or unencrypted data risking data security and analytics reliability",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        }
      ],
      "dataset_metrics_druid": [
        {
          "metric": "druid_supervisors{healthy=\"true\", supervisor_name=\"dataset_id\", state=\"PENDING\"}",
          "alias": "[DATASET]: Druid supervisor is in an unhealthy state",
          "category": "Querying",
          "severity": "critical",
          "code": "QUERY_DRUID_INDEXER_009",
          "description": "An unhealthy Druid Supervisor can halt real-time ingestion, delay data availability and querying.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "druid_ingest_events_unparseable_total{dataSource=\"dataset_id\"}",
          "alias": "[DATASET]: Detected higher amount of unparseable data.",
          "category": "Querying",
          "severity": "critical",
          "code": "QUERY_DRUID_INDEXER_008",
          "description": "High volume of unparseable data can lead to incomplete ingestion, data loss, and gaps in downstream analytics",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "druid_ingest_kafka_lag{dataSource=\"dataset_id\"}",
          "alias": "[DATASET]: Detected higher amount of query lag than expected.",
          "category": "Querying",
          "severity": "critical",
          "code": "QUERY_DRUID_INDEXER_007",
          "description": "Increased query lag in Druid Indexers can affect real-time insights, causing delayed analytics and slower data-driven responses.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 1000
        }
      ],
      "query_metric":[
        {
          "metric": "sum(sum_over_time(node_failed_api_calls{dataset_id='<dataset_id>', id='api.data.out'}[$__range]))",
          "alias": "[DATASET]: The Data Query API is encountering more failures to retrieve the data",
          "category": "Querying",
          "severity": "critical",
          "code": "QUERY_API_005",
          "description": "Failure to query data disrupts access to real-time data, affecting downstream analytics that rely on timely insights.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 0
        },
        {
          "metric": "avg(avg_over_time(node_query_response_time{dataset_id='<dataset_id>', id='api.data.out'}[$__range]))",
          "alias": "[DATASET]: The Data Query API is facing delays in retrieving data",
          "category": "Querying",
          "severity": "critical",
          "code": "QUERY_API_006",
          "description": "Slow queries can delay data retrieval for data analytics.",
          "frequency": "5m",
          "interval": "5m",
          "operator": "gt",
          "threshold": 100
        }
      ]
    }
  }
}